{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Assignment - 2\n",
        "\n",
        "#### Implement all Prompt Engineering approaches- Interview Approach, COT, TOT. Compare and contrast all and analyse their applications.  Implement Zero shot and Few shot prompting and compare their results.\n"
      ],
      "metadata": {
        "id": "BdirOGr0iu9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# About the Model Used\n",
        "\n",
        "## Model Name:\n",
        "gpt-oss-120b\n",
        "\n",
        "## Parameter Size:\n",
        "120 Billion Parameters (120B)\n",
        "\n",
        "## Hosted Via:\n",
        "Clarifai (OpenAI-Compatible API format)\n",
        "\n",
        "## Inferencing LLM from 'clarifai'\n",
        "You will require to get your API key from this [website](https://clarifai.com/openai/chat-completion/models/gpt-oss-120b?tab=runWithApi).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mnWwcjnllau8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRHROhVeiqKw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get Clarifai API Key from Colab secrets\n",
        "CLARIFI_API = userdata.get('CLARIFI_API')\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.clarifai.com/v2/ext/openai/v1\",\n",
        "    api_key=CLARIFI_API,\n",
        ")\n",
        "\n",
        "# Model URL\n",
        "MODEL = \"https://clarifai.com/openai/chat-completion/models/gpt-oss-120b/versions/f1d2ad8c01c74705868f5c8ae4a1ff7c\"\n",
        "\n",
        "def call_llm(messages, temperature=0.7):\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        stream=False,\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interview Approach\n",
        "\n",
        "The Interview Approach gathers information step-by-step before generating a final response.\n",
        "\n",
        "Instead of directly answering, the model asks clarifying questions to better understand context.\n",
        "\n"
      ],
      "metadata": {
        "id": "lD158bKaqPZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interview_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a tech assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Before suggesting a laptop for me, ask 3 questions to understand my needs.\"}\n",
        "]\n",
        "\n",
        "print(\"Interview Approach Output\")\n",
        "print(call_llm(interview_messages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJzQpYpBp1oH",
        "outputId": "5ec8be56-e951-4aa7-9eae-5f46d64d6818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interview Approach Output\n",
            "Sure! To recommend the best laptop for you, could you let me know:\n",
            "\n",
            "1. What will you primarily use the laptop for (e.g., gaming, video editing, software development, everyday office tasks, student work, etc.)?  \n",
            "2. Do you have any preferences or requirements for size, weight, or battery life (e.g., need something ultra‑portable, or a larger screen for multitasking)?  \n",
            "3. What’s your budget range and any specific features you’d like (e.g., touch screen, dedicated graphics, high‑resolution display, specific ports, etc.)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "The model asks clarifying questions instead of directly providing a solution.\n",
        "This demonstrates controlled conversational prompting.\n"
      ],
      "metadata": {
        "id": "OaRt7pFAqhZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain of Thought (CoT)\n",
        "\n",
        "Chain of Thought prompting forces the model to reason step-by-step before giving a final answer.\n",
        "\n",
        "Useful for:\n",
        "- Mathematical reasoning\n",
        "- Logical problems\n",
        "- Multi-step tasks"
      ],
      "metadata": {
        "id": "ujAIhSzuqjks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Solve step by step using plain text only. Do not use LaTeX formatting.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is 25 × 12? Let's think step by step.\"}\n",
        "]\n",
        "\n",
        "print(\"Chain of Thought Output\")\n",
        "print(call_llm(cot_messages))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpTLe6DhqVTK",
        "outputId": "0c36a452-e875-4a2c-fe73-d4ad11350868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain of Thought Output\n",
            "To multiply 25 by 12, break the problem into simpler parts.\n",
            "\n",
            "1. **Separate the multiplier (12) into tens and ones**  \n",
            "   - 12 = 10 + 2  \n",
            "\n",
            "2. **Multiply 25 by each part**  \n",
            "   - 25 × 10 = 250 (just add a zero to 25)  \n",
            "   - 25 × 2 = 50 (because 25 + 25 = 50)  \n",
            "\n",
            "3. **Add the two results together**  \n",
            "   - 250 + 50 = 300  \n",
            "\n",
            "So, 25 × 12 = **300**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "The model explains intermediate reasoning steps before giving the final answer.\n",
        "This improves transparency and reasoning accuracy.\n"
      ],
      "metadata": {
        "id": "f7KBZU7Bqzf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree of Thought (ToT)\n",
        "\n",
        "Tree of Thought prompting explores multiple reasoning paths before selecting the best solution.\n",
        "\n",
        "Unlike CoT (linear reasoning), ToT generates multiple solution branches and evaluates them.\n"
      ],
      "metadata": {
        "id": "sZT_m6d4q1SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tot_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a student mentor.\"},\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "A student wants to improve exam marks.\n",
        "\n",
        "Generate 3 possible strategies.\n",
        "Briefly compare them.\n",
        "Select the best one.\n",
        "\"\"\"}\n",
        "]\n",
        "\n",
        "print(\"Tree of Thought Output\")\n",
        "print(call_llm(tot_messages))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ5Ag74Yqo_5",
        "outputId": "5233e981-76a9-48f4-f352-a9a4f1197fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tree of Thought Output\n",
            "**Three Strategies for Boosting Exam Marks**\n",
            "\n",
            "| # | Strategy | Core Idea | Main Benefits | Potential Drawbacks |\n",
            "|---|----------|-----------|---------------|----------------------|\n",
            "| 1 | **Active‑Recall + Spaced‑Repetition System** (e.g., flashcards, Anki) | Instead of rereading notes, you repeatedly test yourself on the material, and the intervals between reviews grow as you demonstrate mastery. | • Proven to increase long‑term retention <br>• Makes study time highly efficient <br>• Gives immediate feedback on what you truly know | • Requires initial set‑up time to create good cards <br>• May feel “hard” at first, discouraging some learners |\n",
            "| 2 | **Structured Study Schedule + Regular Practice Exams** | Build a weekly calendar that blocks dedicated “focus blocks” for each subject, and embed timed practice tests every 1‑2 weeks. | • Encourages consistent effort and reduces cramming <br>• Practice exams reveal knowledge gaps and improve test‑taking stamina <br>• Helps with time‑management on the actual exam day | • Can become rigid; unexpected events may disrupt the schedule <br>• Quality of practice tests matters – poor questions give misleading signals |\n",
            "| 3 | **Optimized Study Environment & Time‑Management Techniques** (Pomodoro, minimal distractions, ergonomic setup) | Tweak physical and digital surroundings (quiet space, phone‑free, good lighting) and use focused bursts of work (e.g., 25‑minute Pomodoros) followed by short breaks. | • Boosts concentration and reduces fatigue <br>• Simple to implement; no extra materials needed <br>• Works well alongside any other study method | • Alone, it does not address *what* you study, only *how* you study <br>• May be less effective if the underlying study content isn’t organized |\n",
            "\n",
            "---\n",
            "\n",
            "### Brief Comparison\n",
            "\n",
            "| Criterion | Strategy 1 (Active‑Recall) | Strategy 2 (Schedule + Practice Tests) | Strategy 3 (Environment/Time‑Mgmt) |\n",
            "|-----------|----------------------------|----------------------------------------|------------------------------------|\n",
            "| **Retention Impact** | High – forces retrieval, the most powerful memory enhancer | Moderate – repetition helps, but passive review can dominate | Low – improves efficiency, not memory depth |\n",
            "| **Exam‑Skill Development** | Strong (retrieval practice mirrors exam conditions) | Very strong (practice exams simulate real test) | Minimal (focuses on stamina, not knowledge) |\n",
            "| **Time Investment** | Front‑loaded (card creation) then low ongoing cost | Ongoing (regular scheduling & test‑taking) | Low to moderate (setting up space, Pomodoros) |\n",
            "| **Flexibility** | Works anywhere (digital cards) | Needs access to practice material and schedule adherence | Highly adaptable to any subject or schedule |\n",
            "| **Evidence Base** | Extensive cognitive‑psychology research supporting the *testing effect* and *spacing* | Well‑supported by educational research on *distributed practice* and *exam simulation* | Supported for productivity, but indirect effect on marks |\n",
            "\n",
            "---\n",
            "\n",
            "### Selected Best Strategy: **Active‑Recall + Spaced‑Repetition System**\n",
            "\n",
            "**Why it stands out**\n",
            "\n",
            "1. **Maximum learning efficiency** – Retrieval practice yields larger gains per study hour than rereading or highlighting. When combined with spaced intervals, the brain consolidates information far better than massed (crammed) study.\n",
            "2. **Direct alignment with exam demands** – Exams are essentially retrieval tasks. Practicing recall mirrors the cognitive processes required on test day, building both knowledge and confidence.\n",
            "3. **Scalable across subjects** – Whether the exam is factual (biology), conceptual (history), or problem‑solving (math), you can create cards that target definitions, key dates, formulas, or even short problem steps.\n",
            "4. **Built‑in progress tracking** – Modern spaced‑repetition apps automatically show which items you’ve mastered and which need more work, giving you clear, data‑driven feedback.\n",
            "5. **Long‑term benefit** – The same deck can be reused for future courses, making the initial time investment pay off repeatedly.\n",
            "\n",
            "**Implementation Quick‑Start**\n",
            "\n",
            "| Step | Action |\n",
            "|------|--------|\n",
            "| 1 | **Choose a tool** – Anki (free, cross‑platform) or Quizlet (simpler UI). |\n",
            "| 2 | **Create cards** – For each lecture/reading, write a *question* on the front (e.g., “What is the primary function of the mitochondria?”) and the concise answer on the back. Keep cards atomic (one fact per card). |\n",
            "| 3 | **Set a daily review goal** – Start with 15‑20 minutes, aiming for ~30 new cards and reviewing the due ones. |\n",
            "| 4 | **Leverage the spacing algorithm** – Trust the app’s schedule; resist the urge to “study ahead” because the spacing effect works best when you follow the intervals. |\n",
            "| 5 | **Integrate with other habits** – Use a Pomodoro timer for each review session, and schedule a weekly “deep‑dive” where you convert any missed cards into richer explanations or mini‑mind maps. |\n",
            "| 6 | **Monitor progress** – Check the app’s statistics (retention rate, cards due per day). If retention falls below ~80 %, refine the card wording or add context. |\n",
            "\n",
            "By committing to a disciplined active‑recall routine, the student will see a noticeable lift in exam performance within a few weeks, while also building study skills that pay dividends throughout their academic career.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation:\n",
        "The model generates multiple reasoning branches,\n",
        "evaluates them, and selects the most optimal solution.\n",
        "\n",
        "This demonstrates structured multi-path reasoning.\n"
      ],
      "metadata": {
        "id": "dXK5qbk3rH_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison: Interview vs CoT vs ToT\n",
        "\n",
        "| Technique | Reasoning Type | Best For |\n",
        "|------------|---------------|----------|\n",
        "| Interview Approach | Iterative questioning | Requirement clarification |\n",
        "| Chain of Thought | Linear step-by-step reasoning | Math & logic |\n",
        "| Tree of Thought | Multi-path reasoning | Strategic decisions |\n",
        "\n",
        "Conclusion:\n",
        "Prompt structure significantly influences reasoning behavior without changing the underlying model.\n"
      ],
      "metadata": {
        "id": "doHh9aAErLW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot vs Few-shot Prompting\n"
      ],
      "metadata": {
        "id": "QkLDI4virOUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-Shot Prompting\n",
        "\n",
        "**Zero-shot = no examples given.**\n",
        "You just tell the model **what to do**, and it relies purely on its pre-training.\n",
        "\n",
        "### Idea\n",
        "\n",
        "> “You already know this stuff. Just do it.”\n",
        "\n",
        "### Example\n",
        "\n",
        "```text\n",
        "Classify the sentiment of this text as Positive, Negative, or Neutral:\n",
        "\"I love how fast this app is.\"\n"
      ],
      "metadata": {
        "id": "XtUnpVkGrSuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            \"You are a restaurant review classifier. \"\n",
        "            \"For each review, output sentiment and primary issue. \"\n",
        "            \"Format: <Sentiment> - <Issue>. Output only this.\"\n",
        "        ),\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"I never leave this place disappointed. All the dishes are good and well served. \"\n",
        "            \"The staff is attentive and suggests good menu options.\"\n",
        "        ),\n",
        "    },\n",
        "]\n",
        "\n",
        "zero_shot_output = call_llm(zero_shot_messages)\n",
        "print(\"ZERO-SHOT OUTPUT:\", zero_shot_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJOR-GHBqy5J",
        "outputId": "64b01e31-203e-40a8-8055-a4a3c990399f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZERO-SHOT OUTPUT: Positive - Food\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-Shot Prompting\n",
        "\n",
        "**Few-shot = give a few examples** before asking the actual question.\n",
        "\n",
        "### Idea\n",
        "\n",
        "> “Here’s the pattern I want. Follow it.”\n",
        "\n",
        "### Example\n",
        "\n",
        "```text\n",
        "Classify the sentiment of the text.\n",
        "\n",
        "Text: \"This product is terrible.\"\n",
        "Sentiment: Negative\n",
        "\n",
        "Text: \"Amazing experience, will buy again!\"\n",
        "Sentiment: Positive\n",
        "\n",
        "Text: \"The app is okay, nothing special.\"\n",
        "Sentiment:\n",
        "```\n",
        "\n",
        "Model learns the **structure + logic** from examples.\n",
        "\n",
        "### When to use\n",
        "\n",
        "* Task is **nuanced or custom**\n",
        "* You need **consistent formatting**\n",
        "* Domain-specific logic (finance, medical, logs, code, etc.)\n",
        "\n",
        "### Limitations\n",
        "\n",
        "* Longer prompts → higher cost\n",
        "* Too many examples can confuse or bias the model\n"
      ],
      "metadata": {
        "id": "wgpbrxByrbJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": (\n",
        "            \"You are a restaurant review classifier. \"\n",
        "            \"For each review, output sentiment and primary issue. \"\n",
        "            \"Format: <Sentiment> - <Issue>. Output only this.\"\n",
        "            \"None can new be the output, Give whatever you think is best below are some examples\"\n",
        "        ),\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Overall okay. Biriyani was not as good. The rest of the items were good. \"\n",
        "            \"Kadai paneer was too high a price for the quantity served. Ambiance is nice.\"\n",
        "        ),\n",
        "    },\n",
        "    {\"role\": \"assistant\", \"content\": \"Positive - High Price\"},\n",
        "\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"There's no menu card. Staff has to say the menu which makes customers uncomfortable. \"\n",
        "            \"Overall taste wise average and overhyped and overpriced.\"\n",
        "        ),\n",
        "    },\n",
        "    {\"role\": \"assistant\", \"content\": \"Negative - Menu Card Issue\"},\n",
        "\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Food tastes good but the service is very slow and waiting time is high.\"\n",
        "        ),\n",
        "    },\n",
        "    {\"role\": \"assistant\", \"content\": \"Negative - Slow Service\"},\n",
        "\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"The ambiance is beautiful and the staff is polite, but the food quality is inconsistent.\"\n",
        "        ),\n",
        "    },\n",
        "    {\"role\": \"assistant\", \"content\": \"Positive - Food Consistency\"},\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"I never leave this place disappointed. All the dishes are good and well served. \"\n",
        "            \"The staff is attentive and suggests good menu options.\"\n",
        "        ),\n",
        "    },\n",
        "]\n",
        "\n",
        "output = call_llm(few_shot_messages)\n",
        "print(\"MODEL OUTPUT:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvJ9qcZGrYUS",
        "outputId": "bef7169b-583c-4fc6-e23e-d6a4690f7580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL OUTPUT: Positive - No Issue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Comparison & Analysis\n",
        "\n",
        "ANALYSIS\n",
        "========\n",
        "\n",
        "1. Tone & Consistency\n",
        "\n",
        "    Zero-shot:\n",
        "    - Relies purely on the system instruction.\n",
        "    - Tone may vary slightly between runs.\n",
        "    - Persuasion strategy is more generic.\n",
        "\n",
        "    Few-shot:\n",
        "    - Strongly aligned with the provided examples.\n",
        "    - Maintains consistent framing: \"comb as scalp-care & confidence tool\".\n",
        "    - More controlled and predictable sales pitch.\n",
        "\n",
        "2. Creativity vs Control\n",
        "\n",
        "    Zero-shot:\n",
        "    - More creative and flexible.\n",
        "    - Might take unexpected angles.\n",
        "\n",
        "    Few-shot:\n",
        "    - Less creative, more on-rails.\n",
        "    - Follows the demonstrated narrative closely.\n",
        "\n",
        "3. Cost & Prompt Length\n",
        "\n",
        "    Zero-shot:\n",
        "    - Shorter prompt → cheaper and faster.\n",
        "\n",
        "    Few-shot:\n",
        "    - Longer prompt → higher token usage.\n",
        "    - Worth it when precision matters.\n",
        "\n",
        "4. When to Use Which\n",
        "\n",
        "    Use Zero-shot when:\n",
        "    - Task is simple or exploratory.\n",
        "    - You want quick iteration.\n",
        "\n",
        "    Use Few-shot when:\n",
        "    - You need strict tone, format, or logic.\n",
        "    - You're building production agents (sales, support, decisioning).\n",
        "\n",
        "CONCLUSION\n",
        "\n",
        "  - Zero-shot is \"tell the model what to do\".\n",
        "  - Few-shot is \"show the model how to do it\".\n",
        "  \n",
        "    In real systems, a hybrid (clear rules + 1–3 examples) works best."
      ],
      "metadata": {
        "id": "tnrdOvL_rpkh"
      }
    }
  ]
}